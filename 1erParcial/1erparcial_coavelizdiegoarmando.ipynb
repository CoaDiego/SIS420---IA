{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/CoaDiego/SIS420---IA/blob/main/1erParcial/1erparcial_coavelizdiegoarmando.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"xTjmiqnfSxgG"},"source":["# Clasificación multiclase\n","\n","## Introduction\n","\n","En este ejercicio se implementa la regresion one-vs-all y una red neuronal para reconocimiento de digitos.\n","\n","Antes de empezar la ejecución de las partes de codigo correspondienters a los ejercicios, se requiere importar todas las librerias necesarias."]},{"cell_type":"markdown","source":["La escala Fujita Enhance\n","\n","Clasificación\t/ Velocidad del viento\t/ Daño\n","\n","EF0\t/ 65–85 mph\t  / Daños leves\n","\n","EF1\t/ 86–110 mph\t/ Daño moderado\n","\n","EF2\t/ 111–135 mph\t/ Daños considerables\n","\n","EF3\t/ 136–165 mph\t/ Daños graves\n","\n","EF4\t/ 166–200 mph\t/ Daños devastadores\n"],"metadata":{"id":"1w8rA9k2J2A1"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"clyp4NcQycWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726708104749,"user_tz":240,"elapsed":31604,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"4f942d8e-e7d1-4cb7-ae92-09f558833e63"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":104,"metadata":{"id":"20Q29kX8SxgJ","executionInfo":{"status":"ok","timestamp":1726720420610,"user_tz":240,"elapsed":389,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}}},"outputs":[],"source":["# utilizado para la manipulación de directorios y rutas\n","import os\n","\n","# Cálculo científico y vectorial para python\n","import numpy as np\n","\n","# Libreria para graficos\n","from matplotlib import pyplot\n","\n","# Modulo de optimizacion en scipy\n","from scipy import optimize\n","\n","import pandas as pd\n","# le dice a matplotlib que incruste gráficos en el cuaderno\n","%matplotlib inline"]},{"cell_type":"markdown","source":["Pre - Procesamiento de Datos"],"metadata":{"id":"74TdDwIXhov5"}},{"cell_type":"code","source":["# Leer el archivo CSV\n","datos_ds = pd.read_csv('/content/drive/Othercomputers/Mi PC/Semestre 2-2024/SIS420 - INTELIGENCIA ARTIFICIAL I/SIS420---IA/1erParcial/96.US Tornado Dataset 1950-2021/us_tornado_dataset_1950_2021.csv')\n","\n","# Convertir la columna 'date' a datetime\n","datos_ds['date'] = pd.to_datetime(datos_ds['date'])\n","\n","# Extraer mes y día (sin extraer el año)\n","datos_ds['month'] = datos_ds['date'].dt.month\n","datos_ds['day'] = datos_ds['date'].dt.day\n","\n","# Verifica las primeras filas para ver si los días se están asignando correctamente\n","print(datos_ds[['date', 'day', 'month']].head())\n","\n","# Eliminar la columna 'date'\n","datos_ds = datos_ds.drop(columns=['date'])\n","\n","#Mostrar el DataFrame para verificar que 'mag' está al final\n","print(\"DataFrame con la columna 'mag' al final:\")\n","print(datos_ds.head())\n","\n","#Mostrar el DataFrame para verificar\n","print(\"DataFrame con componentes de fecha extraídos:\")\n","print(datos_ds.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ddcDxwaa_3SY","executionInfo":{"status":"ok","timestamp":1726722278277,"user_tz":240,"elapsed":366,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"7c80f69b-ff6f-4a71-974e-d19da2885e1d"},"execution_count":130,"outputs":[{"output_type":"stream","name":"stdout","text":["        date  day  month\n","0 1950-01-03    3      1\n","1 1950-01-03    3      1\n","2 1950-01-03    3      1\n","3 1950-01-13   13      1\n","4 1950-01-25   25      1\n","DataFrame con la columna 'mag' al final:\n","     yr  mo  dy  st  mag  inj  fat   slat   slon   elat   elon  len  wid  \\\n","0  1950   1   3  IL    3    3    0  39.10 -89.30  39.12 -89.23  3.6  130   \n","1  1950   1   3  MO    3    3    0  38.77 -90.22  38.83 -90.03  9.5  150   \n","2  1950   1   3  OH    1    1    0  40.88 -84.58   0.00   0.00  0.1   10   \n","3  1950   1  13  AR    3    1    1  34.40 -94.37   0.00   0.00  0.6   17   \n","4  1950   1  25  IL    2    0    0  41.17 -87.33   0.00   0.00  0.1  100   \n","\n","   month  day  \n","0      1    3  \n","1      1    3  \n","2      1    3  \n","3      1   13  \n","4      1   25  \n","DataFrame con componentes de fecha extraídos:\n","     yr  mo  dy  st  mag  inj  fat   slat   slon   elat   elon  len  wid  \\\n","0  1950   1   3  IL    3    3    0  39.10 -89.30  39.12 -89.23  3.6  130   \n","1  1950   1   3  MO    3    3    0  38.77 -90.22  38.83 -90.03  9.5  150   \n","2  1950   1   3  OH    1    1    0  40.88 -84.58   0.00   0.00  0.1   10   \n","3  1950   1  13  AR    3    1    1  34.40 -94.37   0.00   0.00  0.6   17   \n","4  1950   1  25  IL    2    0    0  41.17 -87.33   0.00   0.00  0.1  100   \n","\n","   month  day  \n","0      1    3  \n","1      1    3  \n","2      1    3  \n","3      1   13  \n","4      1   25  \n"]}]},{"cell_type":"code","source":["print(datos_ds.columns)\n","# Verifica los valores originales de la columna 'mag'\n","print(datos_ds['mag'].head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a27WKttpTUQ8","executionInfo":{"status":"ok","timestamp":1726722280501,"user_tz":240,"elapsed":353,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"d88832c8-11ff-4192-d7df-3f5cdc3d0816"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['yr', 'mo', 'dy', 'st', 'mag', 'inj', 'fat', 'slat', 'slon', 'elat',\n","       'elon', 'len', 'wid', 'month', 'day'],\n","      dtype='object')\n","0    3\n","1    3\n","2    1\n","3    3\n","4    2\n","5    2\n","6    2\n","7    2\n","8    2\n","9    2\n","Name: mag, dtype: int64\n"]}]},{"cell_type":"markdown","source":["1.      Inserte atributos que contengan, caracteres, texto, valores booleanos relacionados a la temática del dataset elegido"],"metadata":{"id":"kkJOwlGOjw4i"}},{"cell_type":"code","source":["# Agregar nuevas columnas:\n","# 1. Columna de texto: Tipo de tornado\n","datos_ds['tipo_tornado'] = ['A' if mag in [1, 2] else 'B' if mag in [3, 4] else 'C' for mag in datos_ds['mag']]\n","\n","#2 Crear una columna booleana 'victimas_M' donde 1 indica víctimas mortales y 0 indica ninguna\n","datos_ds['victimas_M'] = datos_ds['fat'].apply(lambda x: 1 if x > 0 else 0)\n","\n","# Mover la nueva columna 'victimas_M' al final\n","columna_victimas = datos_ds.pop('victimas_M')\n","datos_ds['victimas_M'] = columna_victimas\n","\n","# 3.Definir una función para categorizar la longitud del tornado\n","def categorizar_longitud(longitud):\n","    if longitud < 1:\n","        return 'diminuto'\n","    elif 1 <= longitud < 5:\n","        return 'pequeño'\n","    else:\n","        return 'grande'\n","\n","# Aplicar la función para crear la columna 'tamaño_torn'\n","datos_ds['tamaño_torn'] = datos_ds['len'].apply(categorizar_longitud)\n","\n","# Mover la columna 'tamaño_torn' al final\n","columna_tamaño_torn = datos_ds.pop('tamaño_torn')\n","datos_ds['tamaño_torn'] = columna_tamaño_torn\n","\n","# Mover la columna 'mag' al final del DataFrame\n","columna_mag = datos_ds.pop('mag')  # Extraer la columna 'mag'\n","datos_ds['mag'] = columna_mag      # Añadir la columna 'mag' al final\n","\n","# Mostrar el DataFrame para verificar que la columna 'tamaño_torn' está correctamente añadida y ubicada\n","print(datos_ds.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYEIa5oKjwOS","executionInfo":{"status":"ok","timestamp":1726722293616,"user_tz":240,"elapsed":334,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"72844bde-5282-4e07-9479-ba420c37c0df"},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["     yr  mo  dy  st  inj  fat   slat   slon   elat   elon  len  wid  month  \\\n","0  1950   1   3  IL    3    0  39.10 -89.30  39.12 -89.23  3.6  130      1   \n","1  1950   1   3  MO    3    0  38.77 -90.22  38.83 -90.03  9.5  150      1   \n","2  1950   1   3  OH    1    0  40.88 -84.58   0.00   0.00  0.1   10      1   \n","3  1950   1  13  AR    1    1  34.40 -94.37   0.00   0.00  0.6   17      1   \n","4  1950   1  25  IL    0    0  41.17 -87.33   0.00   0.00  0.1  100      1   \n","\n","   day tipo_tornado  victimas_M tamaño_torn  mag  \n","0    3            B           0     pequeño    3  \n","1    3            B           0      grande    3  \n","2    3            A           0    diminuto    1  \n","3   13            B           1    diminuto    3  \n","4   25            A           0    diminuto    2  \n"]}]},{"cell_type":"markdown","source":["Convertir las columnas de \"st\" , \"tamaño_torn\" y \"tipo_tornado\" a numerico"],"metadata":{"id":"bztESRVxtoEf"}},{"cell_type":"code","source":["# Convertir el DataFrame a un array de NumPy\n","data = datos_ds.to_numpy()\n","# Ahora 'data' es un array de NumPy y puedes realizar operaciones con él"],"metadata":{"id":"1Mq926jdu54o","executionInfo":{"status":"ok","timestamp":1726725829795,"user_tz":240,"elapsed":374,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}}},"execution_count":188,"outputs":[]},{"cell_type":"markdown","source":["st a valor numerico"],"metadata":{"id":"Ue2KSZw-yz4k"}},{"cell_type":"code","source":["# Supongamos que 'data' es tu array de NumPy cargado previamente\n","# y que 'st_column_index' es el índice de la columna 'st'\n","\n","# Crear un diccionario para mapear los valores únicos de 'st'\n","st_column_index = 3  # Ajusta el índice según tu dataset\n","unique_states = np.unique(data[:, st_column_index])\n","state_mapping = {state: idx for idx, state in enumerate(unique_states)}\n","\n","# Aplicar la conversión de texto a números\n","data[:, st_column_index] = np.array([state_mapping[state] for state in data[:, st_column_index]])\n","\n","# Verificar los cambios\n","print(\"Primeras filas del array con la columna 'st':\")\n","print(data[:5, :])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8e9794wBtbzf","executionInfo":{"status":"ok","timestamp":1726725831014,"user_tz":240,"elapsed":2,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"6d979da1-d0cf-4459-97d5-78ab5ce15421"},"execution_count":189,"outputs":[{"output_type":"stream","name":"stdout","text":["Primeras filas del array con la columna 'st':\n","[[1950 1 3 14 3 0 39.1 -89.3 39.12 -89.23 3.6 130 1 3 'B' 0 'pequeño' 3]\n"," [1950 1 3 24 3 0 38.77 -90.22 38.83 -90.03 9.5 150 1 3 'B' 0 'grande' 3]\n"," [1950 1 3 35 1 0 40.88 -84.58 0.0 0.0 0.1 10 1 3 'A' 0 'diminuto' 1]\n"," [1950 1 13 2 1 1 34.4 -94.37 0.0 0.0 0.6 17 1 13 'B' 1 'diminuto' 3]\n"," [1950 1 25 14 0 0 41.17 -87.33 0.0 0.0 0.1 100 1 25 'A' 0 'diminuto' 2]]\n"]}]},{"cell_type":"markdown","source":["tipo_tornado a dato numerico"],"metadata":{"id":"GpqXPv-k1Ch7"}},{"cell_type":"code","source":["# Supongamos que 'data' es tu array de NumPy cargado previamente\n","# Índice de la columna 'tipo_tornado'\n","tipo_tornado_column_index = 14  # Ajusta el índice según tu dataset\n","\n","# Crear un diccionario para mapear 'tipo_tornado' a valores numéricos\n","tipo_tornado_mapping = {'A': 0, 'B': 1, 'C': 2}\n","\n","# Aplicar la conversión de texto a números directamente para 'tipo_tornado'\n","data[:, tipo_tornado_column_index] = np.vectorize(tipo_tornado_mapping.get)(data[:, tipo_tornado_column_index])\n","\n","# Verificar los cambios\n","print(\"Primeras filas del array con la columna 'tipo_tornado':\")\n","print(data[:5, :])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgVkOWOHy4h8","executionInfo":{"status":"ok","timestamp":1726725833146,"user_tz":240,"elapsed":375,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"883362dd-4f96-4093-b6f5-06fb6a28e49e"},"execution_count":190,"outputs":[{"output_type":"stream","name":"stdout","text":["Primeras filas del array con la columna 'tipo_tornado':\n","[[1950 1 3 14 3 0 39.1 -89.3 39.12 -89.23 3.6 130 1 3 1 0 'pequeño' 3]\n"," [1950 1 3 24 3 0 38.77 -90.22 38.83 -90.03 9.5 150 1 3 1 0 'grande' 3]\n"," [1950 1 3 35 1 0 40.88 -84.58 0.0 0.0 0.1 10 1 3 0 0 'diminuto' 1]\n"," [1950 1 13 2 1 1 34.4 -94.37 0.0 0.0 0.6 17 1 13 1 1 'diminuto' 3]\n"," [1950 1 25 14 0 0 41.17 -87.33 0.0 0.0 0.1 100 1 25 0 0 'diminuto' 2]]\n"]}]},{"cell_type":"markdown","source":["tamaño_torn a dato numerico"],"metadata":{"id":"qGJhUtSY1Isj"}},{"cell_type":"code","source":["# Supongamos que 'data' es tu array de NumPy cargado previamente\n","# Índice de la columna 'tamaño_torn'\n","tamaño_torn_column_index = 16  # Ajusta el índice según tu dataset\n","\n","# Crear un diccionario para mapear 'tamaño_torn' a 1, 2 y 3\n","tamaño_mapping = {'diminuto': 1, 'pequeño': 2, 'grande': 3}\n","\n","# Aplicar la conversión de texto a números directamente para 'tamaño_torn'\n","data[:, tamaño_torn_column_index] = np.vectorize(tamaño_mapping.get)(data[:, tamaño_torn_column_index])\n","\n","# Verificar los cambios\n","print(\"Primeras filas del array con las columnas convertidas:\")\n","print(data[:5, :])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5CjGcMmAvzMJ","executionInfo":{"status":"ok","timestamp":1726725834828,"user_tz":240,"elapsed":349,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"036292c7-1b43-412c-d5ac-3cd141dc1f1c"},"execution_count":191,"outputs":[{"output_type":"stream","name":"stdout","text":["Primeras filas del array con las columnas convertidas:\n","[[1950 1 3 14 3 0 39.1 -89.3 39.12 -89.23 3.6 130 1 3 1 0 2 3]\n"," [1950 1 3 24 3 0 38.77 -90.22 38.83 -90.03 9.5 150 1 3 1 0 3 3]\n"," [1950 1 3 35 1 0 40.88 -84.58 0.0 0.0 0.1 10 1 3 0 0 1 1]\n"," [1950 1 13 2 1 1 34.4 -94.37 0.0 0.0 0.6 17 1 13 1 1 1 3]\n"," [1950 1 25 14 0 0 41.17 -87.33 0.0 0.0 0.1 100 1 25 0 0 1 2]]\n"]}]},{"cell_type":"code","source":["# Imprimir las primeras 5 filas del array\n","print(\"Primeras 5 filas del array:\")\n","print(data[:5])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J3-YP4ZLzoU7","executionInfo":{"status":"ok","timestamp":1726725837153,"user_tz":240,"elapsed":387,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"fffb54e0-4828-43ca-cc19-057dae6b39bb"},"execution_count":192,"outputs":[{"output_type":"stream","name":"stdout","text":["Primeras 5 filas del array:\n","[[1950 1 3 14 3 0 39.1 -89.3 39.12 -89.23 3.6 130 1 3 1 0 2 3]\n"," [1950 1 3 24 3 0 38.77 -90.22 38.83 -90.03 9.5 150 1 3 1 0 3 3]\n"," [1950 1 3 35 1 0 40.88 -84.58 0.0 0.0 0.1 10 1 3 0 0 1 1]\n"," [1950 1 13 2 1 1 34.4 -94.37 0.0 0.0 0.6 17 1 13 1 1 1 3]\n"," [1950 1 25 14 0 0 41.17 -87.33 0.0 0.0 0.1 100 1 25 0 0 1 2]]\n"]}]},{"cell_type":"markdown","source":["2.      Duplique los ejemplos del dataset considerando rangos y criterios que garanticen la consistencia del dataset."],"metadata":{"id":"3nWBeS7MtVhw"}},{"cell_type":"markdown","metadata":{"id":"rPiGCmq7SxgK"},"source":["## 1 Clasificación multiclase\n"]},{"cell_type":"code","execution_count":133,"metadata":{"id":"hhRjL2ptSxgK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726722373518,"user_tz":240,"elapsed":368,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"85e055f6-045e-4677-fde9-a4eb3d7a7a09"},"outputs":[{"output_type":"stream","name":"stdout","text":["0    3\n","1    3\n","2    1\n","3    3\n","4    2\n","5    2\n","6    2\n","7    2\n","8    2\n","9    2\n","Name: mag, dtype: int64\n","     yr  mo  dy  st  inj  fat   slat   slon   elat   elon  len  wid  month  \\\n","0  1950   1   3  IL    3    0  39.10 -89.30  39.12 -89.23  3.6  130      1   \n","1  1950   1   3  MO    3    0  38.77 -90.22  38.83 -90.03  9.5  150      1   \n","2  1950   1   3  OH    1    0  40.88 -84.58   0.00   0.00  0.1   10      1   \n","3  1950   1  13  AR    1    1  34.40 -94.37   0.00   0.00  0.6   17      1   \n","4  1950   1  25  IL    0    0  41.17 -87.33   0.00   0.00  0.1  100      1   \n","\n","   day tipo_tornado  victimas_M tamaño_torn  mag  \n","0    3            B           0     pequeño    3  \n","1    3            B           0      grande    3  \n","2    3            A           0    diminuto    1  \n","3   13            B           1    diminuto    3  \n","4   25            A           0    diminuto    2  \n","Número de muestras: 67558\n","Número de características (Input Layer Size): 17\n","Etiquetas únicas en y: [-9  0  1  2  3  4  5]\n","Primeras filas de X:\n","[[1950 1 3 'IL' 3 0 39.1 -89.3 39.12 -89.23 3.6 130 1 3 'B' 0 'pequeño']\n"," [1950 1 3 'MO' 3 0 38.77 -90.22 38.83 -90.03 9.5 150 1 3 'B' 0 'grande']\n"," [1950 1 3 'OH' 1 0 40.88 -84.58 0.0 0.0 0.1 10 1 3 'A' 0 'diminuto']\n"," [1950 1 13 'AR' 1 1 34.4 -94.37 0.0 0.0 0.6 17 1 13 'B' 1 'diminuto']\n"," [1950 1 25 'IL' 0 0 41.17 -87.33 0.0 0.0 0.1 100 1 25 'A' 0 'diminuto']]\n","\n","Primeras filas de y:\n","[3 3 1 3 2 2 2 2 2 2]\n"]}],"source":["# Verifica los valores originales de la columna 'mag'\n","print(datos_ds['mag'].head(10))\n","\n","X = datos_ds.iloc[:, :-1].values  # Todas las columnas excepto la última\n","y = datos_ds.iloc[:, -1].values  # Si 'mag' es la última columna\n","\n","# Asumimos que ya tienes las variables 'X' y 'y' asignadas como en el paso anterior\n","\n","# Configurar las dimensiones de la capa de entrada y las etiquetas\n","input_layer_size = X.shape[1]  # El número de características en X (columnas)\n","num_labels = 5  # Puedes ajustar según la cantidad de clases que tengas en 'y'\n","\n","# Reasignar valores de 'y' cambiar valores de 3 a 0:\n","#y[y == 3] = 0  # Este paso es opcional según el objetivo de la tarea\n","\n","print(datos_ds.head())\n","\n","# Imprimir las dimensiones de X e y para verificar\n","print(f\"Número de muestras: {X.shape[0]}\")\n","print(f\"Número de características (Input Layer Size): {input_layer_size}\")\n","print(f\"Etiquetas únicas en y: {np.unique(y)}\")\n","\n","# Número de muestras\n","m = y.size\n","\n","# Verificar las primeras filas de X e y\n","print(\"Primeras filas de X:\")\n","print(X[:5, :])\n","\n","print(\"\\nPrimeras filas de y:\")\n","print(y[:10])\n","\n"]},{"cell_type":"code","source":["# Duplicar el DataFrame\n","datos_ds_duplicado = pd.concat([datos_ds, datos_ds], ignore_index=True)\n","\n","# Verificar el tamaño del DataFrame duplicado\n","print(f\"Número de filas después de duplicar: {datos_ds_duplicado.shape[0]}\")\n","print(f\"Número de columnas después de duplicar: {datos_ds_duplicado.shape[1]}\")\n","\n","# Verificar las primeras filas para asegurarse de que la duplicación se realizó correctamente\n","print(datos_ds_duplicado.head())\n","\n","# Verificar las últimas filas\n","print(datos_ds_duplicado.tail())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_uGSFaejPEz","executionInfo":{"status":"ok","timestamp":1726722637406,"user_tz":240,"elapsed":375,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}},"outputId":"b0f90e71-6b2c-4c54-ef69-98ba76c6a966"},"execution_count":134,"outputs":[{"output_type":"stream","name":"stdout","text":["Número de filas después de duplicar: 135116\n","Número de columnas después de duplicar: 18\n","     yr  mo  dy  st  inj  fat   slat   slon   elat   elon  len  wid  month  \\\n","0  1950   1   3  IL    3    0  39.10 -89.30  39.12 -89.23  3.6  130      1   \n","1  1950   1   3  MO    3    0  38.77 -90.22  38.83 -90.03  9.5  150      1   \n","2  1950   1   3  OH    1    0  40.88 -84.58   0.00   0.00  0.1   10      1   \n","3  1950   1  13  AR    1    1  34.40 -94.37   0.00   0.00  0.6   17      1   \n","4  1950   1  25  IL    0    0  41.17 -87.33   0.00   0.00  0.1  100      1   \n","\n","   day tipo_tornado  victimas_M tamaño_torn  mag  \n","0    3            B           0     pequeño    3  \n","1    3            B           0      grande    3  \n","2    3            A           0    diminuto    1  \n","3   13            B           1    diminuto    3  \n","4   25            A           0    diminuto    2  \n","          yr  mo  dy  st  inj  fat     slat     slon     elat     elon    len  \\\n","135111  2021  12  30  GA    0    0  31.1703 -83.3804  31.1805 -83.3453   2.19   \n","135112  2021  12  30  GA    0    0  31.6900 -82.7300  31.7439 -82.5412  11.71   \n","135113  2021  12  31  AL    0    0  34.2875 -85.7878  34.2998 -85.7805   0.95   \n","135114  2021  12  31  GA    0    0  33.7372 -84.9998  33.7625 -84.9633   2.75   \n","135115  2021  12  31  GA    6    0  33.5676 -83.9877  33.5842 -83.9498   2.50   \n","\n","        wid  month  day tipo_tornado  victimas_M tamaño_torn  mag  \n","135111  150     12   30            A           0     pequeño    1  \n","135112  300     12   30            A           0      grande    1  \n","135113   50     12   31            A           0    diminuto    1  \n","135114  150     12   31            A           0     pequeño    1  \n","135115   75     12   31            A           0     pequeño    1  \n"]}]},{"cell_type":"code","execution_count":102,"metadata":{"id":"aw2yVc8ESxgL","outputId":"3d8aea6d-2440-4580-f280-d7790c25a8a3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726720205408,"user_tz":240,"elapsed":345,"user":{"displayName":"Diego Armando Coa Veliz","userId":"12701075118815215041"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1950 1 3 'IL' 3 0 39.1 -89.3 39.12 -89.23 3.6 130 1 3]\n","[3 3 1 ... 1 1 1]\n"]}],"source":["print(X[0,:])\n","print(y)"]},{"cell_type":"code","source":["def  featureNormalize(X):\n","    X_norm = X.copy()\n","    mu = np.zeros(X.shape[1])\n","    sigma = np.zeros(X.shape[1])\n","\n","    mu = np.mean(X, axis = 0)\n","    sigma = np.std(X, axis = 0)\n","    X_norm = (X - mu) / sigma\n","\n","    return X_norm, mu, sigma"],"metadata":{"id":"HWF5C5Jt8wNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# llama featureNormalize con los datos cargados\n","X_norm, mu, sigma = featureNormalize(X)"],"metadata":{"id":"f4W6d-ya1ABV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n","m, n = X.shape\n","# Agraga el termino de intercepción a A\n","# X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n","X = X_norm\n","# X = np.concatenate([np.ones((m, 1)), X], axis=1)"],"metadata":{"id":"r9e6MRrW1G22"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxjagbCdSxgL"},"source":["### 1.2 Visualización de los datos\n","\n","Se comenzará visualizando un subconjunto del conjunto de entrenamiento. Se selecciona al azar, 100 filas de `X` y pasa esas filas a la función` displayData`. Esta función asigna cada fila a una imagen en escala de grises de 20 píxeles por 20 píxeles y muestra las imágenes juntas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V2C82bqdSxgL"},"outputs":[],"source":["# def displayData(X, example_width=None, figsize=(10, 10)):\n","#     \"\"\"\n","#     Muestra datos 2D almacenados en X en una cuadrícula apropiada.\n","#     \"\"\"\n","#     # Calcula filas, columnas\n","#     if X.ndim == 2:\n","#         m, n = X.shape\n","#     elif X.ndim == 1:\n","#         n = X.size\n","#         m = 1\n","#         X = X[None]  # Promocionar a una matriz bidimensional\n","#     else:\n","#         raise IndexError('La entrada X debe ser 1 o 2 dimensinal.')\n","\n","#     example_width = example_width or int(np.round(np.sqrt(n)))\n","#     example_height = n / example_width\n","\n","#     # Calcula el numero de elementos a mostrar\n","#     display_rows = int(np.floor(np.sqrt(m)))\n","#     display_cols = int(np.ceil(m / display_rows))\n","\n","#     fig, ax_array = pyplot.subplots(display_rows, display_cols, figsize=figsize)\n","#     fig.subplots_adjust(wspace=0.025, hspace=0.025)\n","\n","#     ax_array = [ax_array] if m == 1 else ax_array.ravel()\n","\n","#     for i, ax in enumerate(ax_array):\n","#         ax.imshow(X[i].reshape(example_width, example_width, order='F'),\n","#                   cmap='Greys', extent=[0, 1, 0, 1])\n","#         ax.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5marXeKSxgM"},"outputs":[],"source":["# Selecciona aleatoriamente 100 puntos de datos para mostrar\n","rand_indices = np.random.choice(m, 100, replace=False)\n","sel = X[rand_indices, :]\n","\n","# displayData(sel)"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"M2h-xWvTSxgM"},"source":["### 1.3 Vectorización de regresión logística\n","\n","Se utilizará múltiples modelos de regresión logística uno contra todos para construir un clasificador de clases múltiples. Dado que hay 10 clases, deberá entrenar 10 clasificadores de regresión logística separados. Para que esta capacitación sea eficiente, es importante asegurarse de que el código esté bien vectorizado.\n","\n","En esta sección, se implementará una versión vectorizada de regresión logística que no emplea ningún bucle \"for\".\n","\n","Para probar la regresión logística vectorizada, se usara datos personalizados como se definen a continuación."]},{"cell_type":"markdown","metadata":{"id":"BQ-PeDkKSxgN"},"source":["<a id=\"section1\"></a>\n","#### 1.3.1 Vectorización de la funcion de costo\n","\n","Se inicia escribiendo una versión vectorizada de la función de costo. En la regresión logística (no regularizada), la función de costo es\n","\n","$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y^{(i)} \\log \\left( h_\\theta\\left( x^{(i)} \\right) \\right) - \\left(1 - y^{(i)} \\right) \\log \\left(1 - h_\\theta \\left( x^{(i)} \\right) \\right) \\right] $$\n","\n","Para calcular cada elemento en la suma, tenemos que calcular $h_\\theta(x^{(i)})$ para cada ejemplo $i$, donde $h_\\theta(x^{(i)}) = g(\\theta^T x^{(i)})$ y $g(z) = \\frac{1}{1+e^{-z}}$ es la funcion sigmoidea. Resulta que podemos calcular esto rápidamente para todos los ejemplos usando la multiplicación de matrices. Definamos $X$ y $\\theta$ como\n","\n","$$ X = \\begin{bmatrix} - \\left( x^{(1)} \\right)^T - \\\\ - \\left( x^{(2)} \\right)^T - \\\\ \\vdots \\\\ - \\left( x^{(m)} \\right)^T - \\end{bmatrix} \\qquad \\text{and} \\qquad \\theta = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\vdots \\\\ \\theta_n \\end{bmatrix} $$\n","\n","Luego, de calcular el producto matricial $X\\theta$, se tiene:\n","\n","$$ X\\theta = \\begin{bmatrix} - \\left( x^{(1)} \\right)^T\\theta - \\\\ - \\left( x^{(2)} \\right)^T\\theta - \\\\ \\vdots \\\\ - \\left( x^{(m)} \\right)^T\\theta - \\end{bmatrix} = \\begin{bmatrix} - \\theta^T x^{(1)}  - \\\\ - \\theta^T x^{(2)} - \\\\ \\vdots \\\\ - \\theta^T x^{(m)}  - \\end{bmatrix} $$\n","\n","En la última igualdad, usamos el hecho de que $a^Tb = b^Ta$ if $a$ y $b$ son vectores. Esto permite calcular los productos $\\theta^T x^{(i)}$ para todos los ejemplos $i$ en una linea de codigo.\n","\n","#### 1.3.2 Vectorización del gradiente\n","\n","Recordemos que el gradiente del costo de regresión logística (no regularizado) es un vector donde el elemento $j^{th}$ se define como\n","$$ \\frac{\\partial J }{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( \\left( h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_j^{(i)} \\right) $$\n","\n","Para vectorizar esta operación sobre el conjunto de datos, se inicia escribiendo todas las derivadas parciales explícitamente para todos $\\theta_j$,\n","\n","$$\n","\\begin{align*}\n","\\begin{bmatrix}\n","\\frac{\\partial J}{\\partial \\theta_0} \\\\\n","\\frac{\\partial J}{\\partial \\theta_1} \\\\\n","\\frac{\\partial J}{\\partial \\theta_2} \\\\\n","\\vdots \\\\\n","\\frac{\\partial J}{\\partial \\theta_n}\n","\\end{bmatrix} = &\n","\\frac{1}{m} \\begin{bmatrix}\n","\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_0^{(i)}\\right) \\\\\n","\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_1^{(i)}\\right) \\\\\n","\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_2^{(i)}\\right) \\\\\n","\\vdots \\\\\n","\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_n^{(i)}\\right) \\\\\n","\\end{bmatrix} \\\\\n","= & \\frac{1}{m} \\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x^{(i)}\\right) \\\\\n","= & \\frac{1}{m} X^T \\left( h_\\theta(x) - y\\right)\n","\\end{align*}\n","$$\n","\n","donde\n","\n","$$  h_\\theta(x) - y =\n","\\begin{bmatrix}\n","h_\\theta\\left(x^{(1)}\\right) - y^{(1)} \\\\\n","h_\\theta\\left(x^{(2)}\\right) - y^{(2)} \\\\\n","\\vdots \\\\\n","h_\\theta\\left(x^{(m)}\\right) - y^{(m)}\n","\\end{bmatrix} $$\n","\n","Nota $x^{(i)}$ es un vector, mientras $h_\\theta\\left(x^{(i)}\\right) - y^{(i)}$ es un escalar(simple número).\n","Para comprender el último paso de la derivación, dejemos $\\beta_i = (h_\\theta\\left(x^{(m)}\\right) - y^{(m)})$ y\n","observar que:\n","\n","$$ \\sum_i \\beta_ix^{(i)} = \\begin{bmatrix}\n","| & | & & | \\\\\n","x^{(1)} & x^{(2)} & \\cdots & x^{(m)} \\\\\n","| & | & & |\n","\\end{bmatrix}\n","\\begin{bmatrix}\n","\\beta_1 \\\\\n","\\beta_2 \\\\\n","\\vdots \\\\\n","\\beta_m\n","\\end{bmatrix} = x^T \\beta\n","$$\n","\n","donde los valores $\\beta_i = \\left( h_\\theta(x^{(i)} - y^{(i)} \\right)$.\n","\n","La expresión anterior nos permite calcular todas las derivadas parciales sin bucles.\n","Si se siente cómodo con el álgebra lineal, le recomendamos que trabaje con las multiplicaciones de matrices anteriores para convencerse de que la versión vectorizada hace los mismos cálculos.\n","\n","<div class=\"alert alert-box alert-warning\">\n","** Consejo de depuración: ** El código de vectorización a veces puede ser complicado. Una estrategia común para la depuración es imprimir los tamaños de las matrices con las que está trabajando usando la propiedad `shape` de las matrices` numpy`.\n","\n","Por ejemplo, dada una matriz de datos $X$ de tamaño $100\\veces 20$ (100 ejemplos, 20 características) y $\\theta$, un vector con tamaño $20$, puede observar que `np.dot (X, theta) `es una operación de multiplicación válida, mientras que` np.dot (theta, X) `no lo es.\n","\n","Además, si tiene una versión no vectorizada de su código, puede comparar la salida de su código vectorizado y el código no vectorizado para asegurarse de que produzcan las mismas salidas.</div>\n","<a id=\"lrCostFunction\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sB9Kyi8SxgN"},"outputs":[],"source":["def sigmoid(z):\n","    \"\"\"\n","    Calcula la sigmoide de z.\n","    \"\"\"\n","    return 1.0 / (1.0 + np.exp(-z))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5S0OOswSxgN"},"outputs":[],"source":["def lrCostFunction(theta, X, y, lambda_):\n","    \"\"\"\n","    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y\n","    el gradiente del costo w.r.t. a los parámetros.\n","\n","    Parametros\n","    ----------\n","    theta : array_like\n","        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas\n","        incluida la intercepcion\n","\n","    X : array_like\n","        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de\n","        caracteristicas (incluida la intercepcion).\n","\n","    y : array_like\n","        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n","\n","    lambda_ : float\n","        Parametro de regularización.\n","\n","    Devuelve\n","    -------\n","    J : float\n","        El valor calculado para la funcion de costo regularizada.\n","\n","    grad : array_like\n","        Un vector de la forma (shape) (n, ) que es el gradiente de la\n","        función de costo con respecto a theta, en los valores actuales de theta..\n","    \"\"\"\n","#     alpha = 0.003\n","#     theta = theta.copy()\n","    # Inicializa algunos valores utiles\n","    m = y.size\n","\n","    # convierte las etiquetas a valores enteros si son boleanos\n","    if y.dtype == bool:\n","        y = y.astype(int)\n","\n","    J = 0\n","    grad = np.zeros(theta.shape)\n","\n","    h = sigmoid(X.dot(theta.T))\n","\n","    temp = theta\n","    temp[0] = 0\n","\n","#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n","    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","\n","    grad = (1 / m) * (h - y).dot(X)\n","#     theta = theta - (alpha / m) * (h - y).dot(X)\n","    grad = grad + (lambda_ / m) * temp\n","\n","    return J, grad\n","#    return J, theta"]},{"cell_type":"markdown","metadata":{"id":"eJyLWCXrSxgN"},"source":["#### 1.3.3 Vectorización regularizada de la regresión logística\n","\n","Una vez implementada la vectorización para la regresión logística, corresponde agregarar regularización a la función de costo.\n","Para la regresión logística regularizada, la función de costo se define como\n","\n","$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y^{(i)} \\log \\left(h_\\theta\\left(x^{(i)} \\right)\\right) - \\left( 1 - y^{(i)} \\right) \\log\\left(1 - h_\\theta \\left(x^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j^2 $$\n","\n","Tomar en cuenta que no debería regularizarse $\\theta_0$ que se usa para el término de sesgo. En consecuencia, la derivada parcial del costo de regresión logística regularizado para $\\theta_j$ se define como\n","\n","$$\n","\\begin{align*}\n","& \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)}  & \\text{for } j = 0 \\\\\n","& \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\left( \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} \\right) + \\frac{\\lambda}{m} \\theta_j & \\text{for } j  \\ge 1\n","\\end{align*}\n","$$\n","\n","<div class=\"alert alert-box alert-warning\">\n","** Python/numpy Consejo: ** Al implementar la vectorización para la regresión logística regularizada, a menudo es posible que solo desee sumar y actualizar ciertos elementos de $\\theta$. En `numpy`, puede indexar en las matrices para acceder y actualizar solo ciertos elementos.\n","\n","Por ejemplo, A [:, 3: 5] = B [:, 1: 3] reemplazará las columnas con índice 3 a 5 de A con las columnas con índice 1 a 3 de B.   \n","Para seleccionar columnas (o filas) hasta el final de la matriz, puede dejar el lado derecho de los dos puntos en blanco.\n","Por ejemplo, A [:, 2:] solo devolverá elementos desde $3^{rd}$ a las últimas columnas de $A$.Si deja el tamaño de la mano izquierda de los dos puntos en blanco, seleccionará los elementos del principio de la matriz.\n","Por ejemplo, A [:,: 2] selecciona las dos primeras columnas y es equivalente a A [:, 0: 2]. Además, puede utilizar índices negativos para indexar matrices desde el final.\n","Por lo tanto, A [:,: -1] selecciona todas las columnas de A excepto la última columna, y A [:, -5:] selecciona la columna $5^{th}$ desde el final hasta la última columna.\n","\n","Por lo tanto, podría usar esto junto con las operaciones de suma y potencia ($^{**}$) para calcular la suma de solo los elementos que le interesan (por ejemplo, `np.sum (z[1:]**2)`).\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"Rlk-Z2p-SxgN"},"source":["<a id=\"section2\"></a>\n","### 1.4 Clasificacion One-vs-all\n","En esta parte del ejercicio, se implementará la clasificación de uno contra todos mediante el entrenamiento de múltiples clasificadores de regresión logística regularizados, uno para cada una de las clases $K$ en nuestro conjunto de datos. En el conjunto de datos de dígitos escritos a mano, $K = 10$, pero su código debería funcionar para cualquier valor de $K$.\n","\n","El argumento `y` de esta función es un vector de etiquetas de 0 a 9. Al entrenar el clasificador para la clase $k \\in \\{0, ..., K-1 \\} $, querrá un vector K-dimensional de etiquetas $y$, donde $y_j \\ in 0, 1$ indica si la instancia de entrenamiento $j ^ {th}$ pertenece a la clase $k$ $(y_j = 1)$, o si pertenece a una clase diferente $(y_j = 0)$.\n","\n","Además, se utiliza `optimize.minimize` de scipy para este ejercicio.\n","<a id=\"oneVsAll\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0rOw5qhSxgN"},"outputs":[],"source":["def oneVsAll(X, y, num_labels, lambda_):\n","    \"\"\"\n","    Trains num_labels logistic regression classifiers and returns\n","    each of these classifiers in a matrix all_theta, where the i-th\n","    row of all_theta corresponds to the classifier for label i.\n","\n","    Parameters\n","    ----------\n","    X : array_like\n","        The input dataset of shape (m x n). m is the number of\n","        data points, and n is the number of features. Note that we\n","        do not assume that the intercept term (or bias) is in X, however\n","        we provide the code below to add the bias term to X.\n","\n","    y : array_like\n","        The data labels. A vector of shape (m, ).\n","\n","    num_labels : int\n","        Number of possible labels.\n","\n","    lambda_ : float\n","        The logistic regularization parameter.\n","\n","    Returns\n","    -------\n","    all_theta : array_like\n","        The trained parameters for logistic regression for each class.\n","        This is a matrix of shape (K x n+1) where K is number of classes\n","        (ie. `numlabels`) and n is number of features without the bias.\n","    \"\"\"\n","    # algunas variables utiles\n","    m, n = X.shape\n","\n","    all_theta = np.zeros((num_labels, n + 1))\n","\n","    # Agrega unos a la matriz X\n","    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","\n","    for c in np.arange(num_labels):\n","        initial_theta = np.zeros(n + 1)\n","        options = {'maxiter': 50}\n","        res = optimize.minimize(lrCostFunction,\n","                                initial_theta,\n","                                (X, (y == c), lambda_),\n","                                jac=True,\n","                                method='CG',\n","                                options=options)\n","\n","        all_theta[c] = res.x\n","\n","    return all_theta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6JbsLLMSxgO","outputId":"12c7d2e9-6465-48ab-db98-050023dd7b42","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["(3, 14)\n"]}],"source":["lambda_ = 0.1\n","all_theta = oneVsAll(X, y, num_labels, lambda_)\n","print(all_theta.shape)"]},{"cell_type":"code","source":["print(all_theta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V1EfKaiEgtcw","outputId":"28c15cf9-d355-4edc-d1e2-76ee84ef38ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-5.9431167   1.09249539  0.62675823  1.428024    0.34141846  0.10314794\n","  -0.15578326 -3.05755875 -0.30526136 -1.12885295  2.07747754 -2.14176945\n","  -2.16418948  0.48815314]\n"," [-2.76714344  2.49719273  0.93966573  1.90491179 -2.81965561  0.29698877\n","   0.45125196  1.63676235 -0.29305502 -0.36107786 -0.13758089 -0.1271495\n","   1.91599118  3.10856368]\n"," [-3.04299407 -2.37084658 -1.20056052 -2.24760854  1.5297807   0.14407858\n","  -0.0378082   1.21702076  1.05250213  0.23120809 -4.38852946  1.71163052\n","  -0.08459958 -3.88470063]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"aQLqvbc_SxgO"},"source":["<a id=\"section3\"></a>\n","#### 1.4.1 Prediccion One-vs-all\n","\n","Después de entrenar el clasificador de one-vs-all, se puede usarlo para predecir el dígito contenido en una imagen determinada. Para cada entrada, debe calcular la \"probabilidad\" de que pertenezca a cada clase utilizando los clasificadores de regresión logística entrenados. La función de predicción one-vs-all seleccionará la clase para la cual el clasificador de regresión logística correspondiente genera la probabilidad más alta y devolverá la etiqueta de clase (0, 1, ..., K-1) como la predicción para el ejemplo de entrada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjFoFe1bSxgO"},"outputs":[],"source":["def predictOneVsAll(all_theta, X):\n","    \"\"\"\n","    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n","    Tenga en cuenta que X contiene los ejemplos en filas.\n","    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase.\n","    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1]\n","    predice clases 0, 2, 0, 1 para 4 ejemplos).\n","\n","    Parametros\n","    ----------\n","    all_theta : array_like\n","        The trained parameters for logistic regression for each class.\n","        This is a matrix of shape (K x n+1) where K is number of classes\n","        and n is number of features without the bias.\n","\n","    X : array_like\n","        Data points to predict their labels. This is a matrix of shape\n","        (m x n) where m is number of data points to predict, and n is number\n","        of features without the bias term. Note we add the bias term for X in\n","        this function.\n","\n","    Devuelve\n","    -------\n","    p : array_like\n","        The predictions for each data point in X. This is a vector of shape (m, ).\n","    \"\"\"\n","\n","    m = X.shape[0];\n","    num_labels = all_theta.shape[0]\n","\n","    p = np.zeros(m)\n","\n","    # Add ones to the X data matrix\n","    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n","\n","    return p"]},{"cell_type":"markdown","metadata":{"id":"zo3aawvsSxgO"},"source":["Una vez que haya terminado, se llama a la función `predictOneVsAll` usando el valor aprendido de $\\theta$. Debería apreciarse que la precisión del conjunto de entrenamiento es de aproximadamente 95,1% (es decir, clasifica correctamente el 95,1% de los ejemplos del conjunto de entrenamiento)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mE7v5cglSxgO","outputId":"d564e268-7adf-4de9-dd3a-e1a85e996ec0","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["(178, 13)\n","Precision del conjuto de entrenamiento: 100.00%\n","(140, 13)\n","(140, 14)\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}],"source":["print(X.shape)\n","pred = predictOneVsAll(all_theta, X)\n","print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n","XPrueba = X[10:150, :].copy()\n","print(XPrueba.shape)\n","#print(np.ones((1)))\n","#print(XPrueba)\n","#p = np.zeros(1)\n","XPrueba = np.concatenate([np.ones((140, 1)), XPrueba], axis=1)\n","print(XPrueba.shape)\n","p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n","print(p)\n","\n","# displayData(X[1002:1003, :])\n","print(y[10:150])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WaT8luNSxgO"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}